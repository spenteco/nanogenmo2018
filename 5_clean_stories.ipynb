{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The generated stories . . . \n",
    "\n",
    ". . . contained a lot of mess.  Here, I try to clean as much of that up as possible.  Then, I scape the sentences into rough paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(stories) 100\n"
     ]
    }
   ],
   "source": [
    "import codecs, re, glob\n",
    "\n",
    "stories = []\n",
    "file_names = []\n",
    "\n",
    "for p in glob.glob('named_stories/*.txt'):\n",
    "    file_names.append(p.split('/')[-1])\n",
    "    stories.append(re.split('\\n', codecs.open(p, 'r', encoding='utf-8').read()))\n",
    "    \n",
    "print 'len(stories)', len(stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import string, re, random\n",
    "\n",
    "def remove_smart_quotes(s):\n",
    "    \n",
    "    new_s = s.replace(u'“', '').replace(u'”', '').replace(u'‘', '').replace(u'’', '').replace(u'#', '').strip()\n",
    "    \n",
    "    if new_s.startswith('- '):\n",
    "        new_s = new_s[2:]\n",
    "        \n",
    "    return new_s\n",
    "\n",
    "def fix_first_letter(s):\n",
    "    \n",
    "    new_s = s\n",
    "    \n",
    "    if len(new_s) > 0:\n",
    "        if s[0].lower() == s[0]:\n",
    "            new_s = new_s[0].upper() + new_s[1:]\n",
    "            \n",
    "        if s[0] in string.punctuation:\n",
    "            new_s = new_s[1:].strip()\n",
    "        \n",
    "    return new_s.strip()\n",
    "\n",
    "def fix_elipses(s):\n",
    "    \n",
    "    return s.replace(u'....', ' . . .').strip()\n",
    "    \n",
    "def fix_starting_digits(s):\n",
    "    \n",
    "    return re.sub('^[0-9]*', '', s).strip()\n",
    "\n",
    "def fix_busted_apostrophes(s):\n",
    "    \n",
    "    new_s = s\n",
    "    \n",
    "    new_s = new_s.replace('\\' own tongue', '\\'s own tongue')\n",
    "    new_s = new_s.replace('\\' thin lips', '\\'s thin lips')\n",
    "    new_s = new_s.replace('\\' normally handsome', '\\'s normally handsome')\n",
    "    new_s = new_s.replace('\\' keen Colin', '\\'s keen Colin')\n",
    "    new_s = new_s.replace('\\' old friends', '\\'s old friends')\n",
    "    new_s = new_s.replace('Dimension?\\' \\' I have', 'Dimension? I have')\n",
    "    new_s = new_s.replace('-- Cyrus Rana . \\'', '-- Cyrus Rana')\n",
    "    new_s = new_s.replace('\\' long legs', '\\'s long legs')\n",
    "    new_s = new_s.replace('\\' keen eyes', '\\'s keen eyes')\n",
    "    \n",
    "    #if new_s.find('\\' ') > -1:\n",
    "    #    print\n",
    "    #    print new_s\n",
    "        \n",
    "    return new_s.strip()\n",
    "    \n",
    "def replace_bad_word(s):\n",
    "    \n",
    "    # FROM https://github.com/dariusk/wordfilter/blob/master/lib/badwords.json\n",
    "    \n",
    "    bad_words = [\"beeyotch\", \"biatch\", \"bitch\", \"chinaman\", \n",
    "                 \"chinamen\", \"chink\", \"crazie\", \"crazy\", \"crip\", \n",
    "                 \"cunt\", \"dago\", \"daygo\", \"dego\", \"dick\", \"dumb\", \n",
    "                 \"douchebag\", \n",
    "                 #\"dyke\",   # SOMEONE HAS A Van Dyke beard\n",
    "                 \"fag\", \"fatass\", \"fatso\", \n",
    "                 #\"gash\", # NOT A PROBLEM \n",
    "                 \"gimp\", \"golliwog\", \"gook\", \"gyp\", \"halfbreed\", \n",
    "                 \"half-breed\", \n",
    "                 #\"homo\", # SAPIENS\n",
    "                 \"hooker\", \"idiot\", \"insane\", \n",
    "                 \"insanitie\", \"insanity\", \"jap\", \"kike\", \"kraut\", \n",
    "                 \"lame\", \"lardass\", \"lesbo\", \"lunatic\", \"negro\", \n",
    "                 \"nigga\", \"nigger\", \"nigguh\", \"paki\", \"pickaninnie\", \n",
    "                 \"pickaninny\", \"pussie\", \"pussy\", \"raghead\", \n",
    "                 #\"retard\", # A VERB\n",
    "                 \"shemale\", \"skank\", \"slut\", \"spade\", \"spic\", \"spook\", \n",
    "                 \"tard\", \"tits\", \"titt\", \"trannie\", \"tranny\", \"twat\", \n",
    "                 \"wetback\", \"whore\", \"wop\" ]\n",
    "    \n",
    "    new_s = s\n",
    "    \n",
    "    new_s = re.sub(r'\\bcrazy\\b', 'mistaken', new_s)\n",
    "    new_s = re.sub(r'\\bChinamen\\b', 'Centarians', new_s)\n",
    "    new_s = re.sub(r'\\bJap\\b', 'Centarian', new_s)\n",
    "    new_s = re.sub(r'\\bidiot\\b', 'fool', new_s)\n",
    "    new_s = re.sub(r'\\bnegro\\b', 'Centarian', new_s)\n",
    "    new_s = re.sub(r'\\bspade\\b', 'grin', new_s)\n",
    "    new_s = re.sub(r'\\binsane\\b', 'mistaken', new_s)\n",
    "    new_s = re.sub(r'\\bSpook\\b', 'Cutlery', new_s)\n",
    "    new_s = re.sub(r'\\binsanity\\b', 'incoherence', new_s)\n",
    "    new_s = re.sub(r'March.\\'  Woman', 'March.  Woman', new_s)\n",
    "    new_s = re.sub('North Pole March.\\'', 'North Pole March.', new_s)\n",
    "    \n",
    "    test_new_s = new_s.lower()\n",
    "    \n",
    "    for b in bad_words:\n",
    "        if len(re.findall(r'\\b' + b + r'\\b', test_new_s)) > 0:\n",
    "            print\n",
    "            print b, new_s\n",
    "        \n",
    "    return new_s.strip()\n",
    "\n",
    "def fix_missing_terminal_punctuation(s):\n",
    "    \n",
    "    new_s = s.strip()\n",
    "    \n",
    "    if len(new_s) > 0:\n",
    "    \n",
    "        if new_s[-1] not in string.punctuation:\n",
    "            new_s = new_s + random.choice(['.', '?', '!'])\n",
    "        \n",
    "    return new_s\n",
    "\n",
    "# -------------------------------------------------------------------------------------\n",
    "\n",
    "for a in range(0, len(stories)):\n",
    "    for b in range(0, len(stories[a])):\n",
    "        \n",
    "        stories[a][b] = remove_smart_quotes(stories[a][b])\n",
    "        stories[a][b] = fix_first_letter(stories[a][b])\n",
    "        stories[a][b] = fix_elipses(stories[a][b])\n",
    "        stories[a][b] = fix_starting_digits(stories[a][b])\n",
    "        stories[a][b] = fix_busted_apostrophes(stories[a][b])\n",
    "        stories[a][b] = replace_bad_word(stories[a][b])\n",
    "        stories[a][b] = fix_missing_terminal_punctuation(stories[a][b])\n",
    "        \n",
    "        \n",
    "print 'Done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for a in range(0, len(stories)):\n",
    "    \n",
    "    final_story = []\n",
    "    for sentence in stories[a]:\n",
    "        \n",
    "        if sentence > '':\n",
    "        \n",
    "            if len(final_story) == 0:\n",
    "                final_story.append([sentence])\n",
    "            else:\n",
    "                #if random.randint(1, 2) == 1:\n",
    "                if len(' '.join(final_story[-1])) < random.randint(10, 250):\n",
    "                    final_story[-1].append(sentence)\n",
    "                else:\n",
    "                    final_story.append([sentence])\n",
    "    \n",
    "    f = codecs.open('cleaned_stories/' + file_names[a], 'w', encoding='utf-8')\n",
    "    \n",
    "    for p in final_story:\n",
    "        f.write('  '.join(p) + '\\n\\n')\n",
    "        \n",
    "    f.close()\n",
    "        \n",
    "print 'Done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
